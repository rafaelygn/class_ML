{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exploring:\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        \n",
    "    def corr_matrix(self, target=None, heatmap=None, **kwargs_plot):\n",
    "        corr_matrix = self.dataset.corr()\n",
    "        if target: \n",
    "            result = corr_matrix[target].sort_values(ascending=False)\n",
    "            return pd.DataFrame(result)\n",
    "        elif heatmap:\n",
    "            import seaborn as sns\n",
    "            fig, ax = plt.subplots(figsize=(12,8))\n",
    "            sns.heatmap(corr_matrix, alpha=.9, cmap=plt.get_cmap(\"coolwarm\"), **kwargs_plot)\n",
    "            return None\n",
    "        else:\n",
    "            return corr_matrix\n",
    "        \n",
    "    def plot_corr_matrix(self, subset=None, **kwargs_plot):\n",
    "        from pandas.plotting import scatter_matrix as scatter_matrix\n",
    "        if subset:\n",
    "            scatter_matrix(self.dataset[subset],figsize=(12,8), **kwargs_plot)\n",
    "            plt.show()\n",
    "            return None\n",
    "        else:\n",
    "            scatter_matrix(self.dataset,figsize=(12,8))\n",
    "            plt.show()\n",
    "            return None\n",
    "    \n",
    "    def plot_geo(self, x, y, var, **kwargs_plot):\n",
    "        from matplotlib import pyplot as plt\n",
    "        x_value = self.dataset[x]\n",
    "        y_value = self.dataset[y]\n",
    "        z_value = self.dataset[var]\n",
    "        fig, ax = plt.subplots(figsize=(12,8))\n",
    "        ax_color = ax.scatter(x_value, y_value, \n",
    "                    c=z_value,\n",
    "                    label=var,\n",
    "                    cmap=plt.get_cmap(\"jet\"),\n",
    "                    **kwargs_plot)\n",
    "        cbar = fig.colorbar(ax_color)\n",
    "        ax.set_xlabel(x)\n",
    "        ax.set_ylabel(y)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        return None\n",
    "\n",
    "    def plot_percentil(self, var1, var2, percentiles=[.25, .50, .75], table=None, **kwargs_plot):\n",
    "        array_percentil = self.dataset[var1].describe(percentiles)\n",
    "        index_percentil = list(str(int(per*100)).replace('0.', '')+'%' for per in percentiles)\n",
    "        label = index_percentil + ['max']\n",
    "        self.dataset['group_'+var1] = pd.cut(self.dataset[var1],\n",
    "                                       bins=array_percentil[['min']+index_percentil+['max']],\n",
    "                                       labels=label)\n",
    "        df_mean  = pd.DataFrame(self.dataset.groupby(by='group_'+var1)[var2].mean())\n",
    "        df_count = pd.DataFrame(self.dataset.groupby(by='group_'+var1)[var2].count())\n",
    "        df_std   = pd.DataFrame(self.dataset.groupby(by='group_'+var1)[var2].std())\n",
    "        \n",
    "        df_final = df_mean.join(df_count, rsuffix='_count').join(df_std, rsuffix='_std')\n",
    "        if table:\n",
    "            return df_final\n",
    "        else:\n",
    "            df_final[var2+'_std_upper'] = df_final[var2] + df_final[var2+'_std']/2\n",
    "            df_final[var2+'_std_lower'] = df_final[var2] - df_final[var2+'_std']/2\n",
    "            x = np.arange(df_final.shape[0])\n",
    "            y = df_final[var2]\n",
    "            y2 = df_final[var2+'_count']\n",
    "            std = df_final[var2+'_std']\n",
    "            std_upper = df_final[var2+'_std_upper']\n",
    "            std_lower = df_final[var2+'_std_lower']\n",
    "            fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "            ax1.plot(x, y, color='black', alpha=0.6)\n",
    "            ax1.plot(x, std_lower, color='black', alpha=0.3)\n",
    "            #ax1.stackplot(x, std_upper, std_lower)\n",
    "            ax1.plot(x, std_upper, color='black', alpha=0.3)\n",
    "            ax1.set_xlabel('Percentil '+var1)\n",
    "            ax1.set_ylabel('mean_'+var2)\n",
    "            ax2 = ax1.twinx()\n",
    "            ax2.set_ylabel('Volumetria')\n",
    "            ax2.bar(x, y2, width=0.2, alpha=.3, color='green')\n",
    "            plt.xticks(x, label)\n",
    "            return None\n",
    "\n",
    "    def boxplot_normalized(self, drop_columns=None):\n",
    "        df_numerical = self.dataset._get_numeric_data()\n",
    "        df_box = (df_numerical - df_numerical.mean())/df_numerical.std()\n",
    "        if drop_columns:\n",
    "            df_box.drop(drop_columns, axis=1, inplace=True)\n",
    "        fig, ax1 = plt.subplots(figsize=(12,8))\n",
    "        sns.boxplot(data=df_box)\n",
    "        plt.show()\n",
    "        return None\n",
    "        \n",
    "    def data_info(self):\n",
    "        info = pd.DataFrame()\n",
    "        info[\"var\"] = self.dataset.columns\n",
    "        info[\"# missing\"] = list(self.dataset.isnull().sum())\n",
    "        info[\"% missing\"] = info[\"# missing\"] / self.dataset.shape[0]*100\n",
    "        info[\"types\"] = list(self.dataset.dtypes)\n",
    "        info[\"unique values\"] = list(len(self.dataset[var].unique()) for var in self.dataset.columns)\n",
    "        return info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "class premodeling:\n",
    "    # Importing libs\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "\n",
    "    def __init__(self, dataset, index_cols=None, ignore_cols=None, drop_cols=None):\n",
    "        '''\n",
    "        Here we define what will be index, cat_cols, cat_cols_used and drop columns\n",
    "        '''\n",
    "        self.dataset = dataset.copy()\n",
    "        # Set index columns\n",
    "        if index_cols:\n",
    "            self.dataset.set_index(index_cols, inplace=True)\n",
    "        # Drop columns in drop_cols\n",
    "        if drop_cols:\n",
    "            self.dataset.drop(labels=drop_cols, axis=1, inplace=True)\n",
    "        # Set importants features\n",
    "        self.cat_cols = self.dataset.select_dtypes(include='object').columns.tolist()\n",
    "        self.num_cols = self.dataset.select_dtypes(exclude='object').columns.tolist()\n",
    "        if ignore_cols:\n",
    "            # Use all categories unless ignore cols\n",
    "            self.cat_cols_used = [col for col in self.cat_cols if col not in ignore_cols]\n",
    "            self.num_cols_used = [col for col in self.num_cols if col not in ignore_cols]\n",
    "        else:\n",
    "            # Use all categories columns\n",
    "            self.cat_cols_used = self.cat_cols\n",
    "            self.num_cols_used = self.num_cols\n",
    "        \n",
    "    def fill_missing(self, na_cat='desconhecido', na_num='mean'):\n",
    "        '''\n",
    "        Preenche valores nulos para valores categóricos com 'desconhecido'\n",
    "        e para valores numéricos com a média.\n",
    "\n",
    "        Para escorar o teste, os valores das médias vão estar salvos\n",
    "        no train_mean.\n",
    "        '''\n",
    "        self.train_mean = self.dataset[self.num_cols_used].mean()\n",
    "        if na_cat:\n",
    "            self.dataset[self.cat_cols_used] = self.dataset[self.cat_cols_used].fillna(\n",
    "                value=na_cat, axis=1)\n",
    "        if na_num:\n",
    "            self.dataset[self.num_cols_used] = self.dataset[self.num_cols_used].fillna(\n",
    "                value=self.dataset[self.num_cols_used].mean())\n",
    "        return self.dataset\n",
    "\n",
    "    def encoding_others(self, per_others=0, cat_cols=None, other_name='Outros',\n",
    "                 ignore_cols=None, index_cols=None):\n",
    "        '''\n",
    "        Codificamos os valores categoricos com ocorrência menor que min_others\n",
    "        por 'Outros'\n",
    "        '''\n",
    "        if cat_cols:\n",
    "            # Use some categories columns\n",
    "            self.cat_cols_used_other = [col for col in self.cat_cols_used if col in ignore_cols]\n",
    "        else:\n",
    "            # Use all categories columns\n",
    "            self.cat_cols_used_other = self.cat_cols_used\n",
    "        # Creating a log dictionary\n",
    "        self.dict_log = {}\n",
    "        # Mapping and saving in self.dict_log\n",
    "        for col in self.cat_cols_used_other:\n",
    "            var = self.dataset[col].value_counts(normalize=True)*100\n",
    "            self.dict_log[col] = var[var > per_others].index.tolist()\n",
    "        # What isn't in dict_log, replace by 'other_name'\n",
    "        for col in self.dict_log.keys():\n",
    "            self.dataset[col] = self.dataset[col].apply(\n",
    "                lambda x: x if x in self.dict_log.get(col) else other_name)\n",
    "        return self.dataset\n",
    "    \n",
    "    def encoding_OneHot(self, cat_cols=None, drop_cat=True):\n",
    "        if cat_cols:\n",
    "        # Use some categories columns\n",
    "            self.cat_cols_used_encoding = [col for col in self.cat_cols_used if col in cat_cols]\n",
    "        else:\n",
    "            # Use all categories columns\n",
    "            self.cat_cols_used_encoding = self.cat_cols_used\n",
    "        import re\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(self.dataset[self.cat_cols_used_encoding])\n",
    "        a_encoding = enc.transform(self.dataset[self.cat_cols_used_encoding]).toarray()\n",
    "        # Take the columns Name\n",
    "        enc_name = enc.get_feature_names().tolist()\n",
    "        col_name = []\n",
    "        for num, col in zip(range(len(self.dataset[self.cat_cols_used_encoding])), self.dataset[self.cat_cols_used_encoding]):\n",
    "            partial_col_name = [name.replace(re.findall('x[0-9]+',name)[0], col) for name in enc_name if re.findall('[0-9]+',name)[0]==str(num)]\n",
    "            col_name += partial_col_name\n",
    "        df_encoding = pd.DataFrame(a_encoding, columns=col_name)\n",
    "        #return self.dataset, enc, a_encoding, col_name\n",
    "        for col in col_name:\n",
    "            self.dataset[col] = df_encoding[col].values\n",
    "        if drop_cat:\n",
    "            self.dataset.drop(labels=self.cat_cols_used_encoding, axis=1, inplace=True)\n",
    "        return self.dataset, enc\n",
    "    \n",
    "    def encoding_mean_rate(self, target, cat_cols=None, min_obs=100):\n",
    "        if cat_cols:\n",
    "        # Use some categories columns\n",
    "            self.cat_cols_used_meanrate = [col for col in self.cat_cols_used if col in cat_cols]\n",
    "        else:\n",
    "            # Use all categories columns\n",
    "            self.cat_cols_used_meanrate = self.cat_cols_used\n",
    "        \n",
    "        for col in self.cat_cols_used_meanrate:\n",
    "            df_mean = pd.DataFrame(self.dataset.groupby([col])[target].mean())\n",
    "            df_mean.columns = [col+'_mean']\n",
    "            df_count = pd.DataFrame(self.dataset.groupby([col])[target].count())\n",
    "            df_count.columns = [col+'_count']\n",
    "            df_result = df_mean.join(df_count)\n",
    "            df_result = df_result[df_result[col+'_count']>min_obs]\n",
    "            self.dataset = self.dataset.join(df_result[col+'_mean'], on=[col])\n",
    "            self.num_cols_used.append(col+'_mean')\n",
    "    \n",
    "    def encoding_label(self, target, str_target):\n",
    "        n = len(self.dataset[target].unique())\n",
    "        print(n)\n",
    "        if n != 2:\n",
    "            print('FAIL. nº de features: ',n)\n",
    "            return None\n",
    "        else:\n",
    "            self.dataset[target].apply(lambda x: 1 if x==str_target else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Goodwin, Miss. Lillian Amy</td>\n",
       "      <td>female</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>CA 2144</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Frederick</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Slocovski, Mr. Selman Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392086</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>655</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Hegarty, Miss. Hanora \"Nora\"</td>\n",
       "      <td>female</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365226</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>528</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Farthing, Mr. John</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17483</td>\n",
       "      <td>221.7792</td>\n",
       "      <td>C95</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>847</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Mr. Douglas Bullen</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Richard, Mr. Emile</td>\n",
       "      <td>male</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2133</td>\n",
       "      <td>15.0458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>414</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Cunningham, Mr. Alfred Fleming</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239853</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>115</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Attalah, Miss. Malake</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2627</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "71            72         0       3   \n",
       "201          202         0       3   \n",
       "18            19         0       3   \n",
       "87            88         0       3   \n",
       "654          655         0       3   \n",
       "527          528         0       1   \n",
       "846          847         0       3   \n",
       "135          136         0       2   \n",
       "413          414         0       2   \n",
       "114          115         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "71                          Goodwin, Miss. Lillian Amy  female  16.0      5   \n",
       "201                                Sage, Mr. Frederick    male   NaN      8   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "87                       Slocovski, Mr. Selman Francis    male   NaN      0   \n",
       "654                       Hegarty, Miss. Hanora \"Nora\"  female  18.0      0   \n",
       "527                                 Farthing, Mr. John    male   NaN      0   \n",
       "846                           Sage, Mr. Douglas Bullen    male   NaN      8   \n",
       "135                                 Richard, Mr. Emile    male  23.0      0   \n",
       "413                     Cunningham, Mr. Alfred Fleming    male   NaN      0   \n",
       "114                              Attalah, Miss. Malake  female  17.0      0   \n",
       "\n",
       "     Parch           Ticket      Fare Cabin Embarked  \n",
       "71       2          CA 2144   46.9000   NaN        S  \n",
       "201      2         CA. 2343   69.5500   NaN        S  \n",
       "18       0           345763   18.0000   NaN        S  \n",
       "87       0  SOTON/OQ 392086    8.0500   NaN        S  \n",
       "654      0           365226    6.7500   NaN        Q  \n",
       "527      0         PC 17483  221.7792   C95        S  \n",
       "846      2         CA. 2343   69.5500   NaN        S  \n",
       "135      0    SC/PARIS 2133   15.0458   NaN        C  \n",
       "413      0           239853    0.0000   NaN        S  \n",
       "114      0             2627   14.4583   NaN        C  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Dataset: \n",
      "\n",
      "            var  # missing  % missing    types  unique values\n",
      "0   PassengerId          0   0.000000    int64            891\n",
      "1      Survived          0   0.000000    int64              2\n",
      "2        Pclass          0   0.000000    int64              3\n",
      "3          Name          0   0.000000   object            891\n",
      "4           Sex          0   0.000000   object              2\n",
      "5           Age        177  19.865320  float64             89\n",
      "6         SibSp          0   0.000000    int64              7\n",
      "7         Parch          0   0.000000    int64              7\n",
      "8        Ticket          0   0.000000   object            681\n",
      "9          Fare          0   0.000000  float64            248\n",
      "10        Cabin        687  77.104377   object            148\n",
      "11     Embarked          2   0.224467   object              4\n",
      "\n",
      "__ini___ Dataset: \n",
      "\n",
      "        var  # missing  % missing    types  unique values\n",
      "0  Survived          0   0.000000    int64              2\n",
      "1    Pclass          0   0.000000    int64              3\n",
      "2       Sex          0   0.000000   object              2\n",
      "3       Age        177  19.865320  float64             89\n",
      "4     SibSp          0   0.000000    int64              7\n",
      "5     Parch          0   0.000000    int64              7\n",
      "6      Fare          0   0.000000  float64            248\n",
      "7     Cabin        687  77.104377   object            148\n",
      "8  Embarked          2   0.224467   object              4\n",
      "\n",
      "encoding_others Dataset:\n",
      "        var  # missing  % missing    types  unique values\n",
      "0  Survived          0    0.00000    int64              2\n",
      "1    Pclass          0    0.00000    int64              3\n",
      "2       Sex          0    0.00000   object              2\n",
      "3       Age        177   19.86532  float64             89\n",
      "4     SibSp          0    0.00000    int64              7\n",
      "5     Parch          0    0.00000    int64              7\n",
      "6      Fare          0    0.00000  float64            248\n",
      "7     Cabin          0    0.00000   object              1\n",
      "8  Embarked          0    0.00000   object              3\n",
      "\n",
      "encoding_mean_rate Dataset: \n",
      "\n",
      "              var  # missing  % missing    types  unique values\n",
      "0        Survived          0   0.000000    int64              2\n",
      "1          Pclass          0   0.000000    int64              3\n",
      "2             Sex          0   0.000000   object              2\n",
      "3             Age        177  19.865320  float64             89\n",
      "4           SibSp          0   0.000000    int64              7\n",
      "5           Parch          0   0.000000    int64              7\n",
      "6            Fare          0   0.000000  float64            248\n",
      "7           Cabin          0   0.000000   object              1\n",
      "8        Embarked          0   0.000000   object              3\n",
      "9        Sex_mean          0   0.000000  float64              2\n",
      "10     Cabin_mean          0   0.000000  float64              1\n",
      "11  Embarked_mean         79   8.866442  float64              3\n",
      "\n",
      "fill_missing Dataset: \n",
      "\n",
      "              var  # missing  % missing    types  unique values\n",
      "0        Survived          0        0.0    int64              2\n",
      "1          Pclass          0        0.0    int64              3\n",
      "2             Sex          0        0.0   object              2\n",
      "3             Age          0        0.0  float64             89\n",
      "4           SibSp          0        0.0    int64              7\n",
      "5           Parch          0        0.0    int64              7\n",
      "6            Fare          0        0.0  float64            248\n",
      "7           Cabin          0        0.0   object              1\n",
      "8        Embarked          0        0.0   object              3\n",
      "9        Sex_mean          0        0.0  float64              2\n",
      "10     Cabin_mean          0        0.0  float64              1\n",
      "11  Embarked_mean          0        0.0  float64              3\n",
      "\n",
      "encoding_OneH Dataset:\n",
      "                var  # missing  % missing    types  unique values\n",
      "0          Survived          0        0.0    int64              2\n",
      "1            Pclass          0        0.0    int64              3\n",
      "2               Age          0        0.0  float64             89\n",
      "3             SibSp          0        0.0    int64              7\n",
      "4             Parch          0        0.0    int64              7\n",
      "5              Fare          0        0.0  float64            248\n",
      "6          Sex_mean          0        0.0  float64              2\n",
      "7        Cabin_mean          0        0.0  float64              1\n",
      "8     Embarked_mean          0        0.0  float64              3\n",
      "9        Sex_female          0        0.0  float64              2\n",
      "10         Sex_male          0        0.0  float64              2\n",
      "11     Cabin_Outros          0        0.0  float64              1\n",
      "12       Embarked_C          0        0.0  float64              2\n",
      "13  Embarked_Outros          0        0.0  float64              2\n",
      "14       Embarked_S          0        0.0  float64              2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\Rafael\\\\Desktop\\\\Data Science\\\\Dataset\\\\titanic\\\\train.csv')\n",
    "\n",
    "print('Raw Dataset: \\n')\n",
    "print(Exploring(df).data_info())\n",
    "\n",
    "ob = premodeling(df,index_cols=['PassengerId'], drop_cols=['Name', 'Ticket'], ignore_cols=['Survived'])\n",
    "print('\\n__ini___ Dataset: \\n')\n",
    "print(Exploring(ob.dataset).data_info())\n",
    "\n",
    "ob.encoding_others(per_others=10)\n",
    "print('\\nencoding_others Dataset:')\n",
    "print(Exploring(ob.dataset).data_info())\n",
    "\n",
    "ob.encoding_mean_rate('Survived', min_obs=100)\n",
    "print('\\nencoding_mean_rate Dataset: \\n')\n",
    "print(Exploring(ob.dataset).data_info())\n",
    "\n",
    "ob.fill_missing()\n",
    "print('\\nfill_missing Dataset: \\n')\n",
    "print(Exploring(ob.dataset).data_info())\n",
    "\n",
    "data, enc = ob.encoding_OneHot()\n",
    "print('\\nencoding_OneH Dataset:')\n",
    "print(Exploring(ob.dataset).data_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cl_modeling:\n",
    "    \n",
    "    def __init__(self, X_train, y_train, X_test, y_test):\n",
    "        self.X_train = X_train.copy()\n",
    "        self.y_train = y_train.copy()\n",
    "        self.X_test = X_test.copy()\n",
    "        self.y_test = y_test.copy()\n",
    "    \n",
    "    def train_predict_model(self, model):\n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        \n",
    "        from sklearn.metrics import roc_curve\n",
    "        from sklearn.metrics import roc_auc_score, confusion_matrix\n",
    "        from sklearn.metrics import accuracy_score, f1_score\n",
    "        from sklearn.metrics import precision_score, recall_score\n",
    "        \n",
    "        print(\"Precision: \", precision_score(y_test, y_pred))\n",
    "        print(\"Recall: \", recall_score(y_test, y_pred))\n",
    "        print(\"Accuracy: \", accuracy_score(y_test, y_pred))\n",
    "        print(\"F1: \", f1_score(y_test, y_pred))\n",
    "        print(\"AUC: \", roc_auc_score(y_test, y_pred_proba[:, 1]))\n",
    "        print(\"Confusion Matrix: \\n \",confusion_matrix(y_test, y_pred))\n",
    "    \n",
    "    def multi_default_models(self, models=None):\n",
    "        if models:\n",
    "            for model in models:\n",
    "                print(model)\n",
    "                ob2.train_predict_model(model)\n",
    "                print()\n",
    "        else:\n",
    "            ob2 = modeling(self.X_train, self.X_test, self.y_train, self.y_test)\n",
    "            from sklearn.ensemble import RandomForestClassifier\n",
    "            from sklearn.linear_model import LogisticRegression\n",
    "            from sklearn.naive_bayes import GaussianNB\n",
    "            from sklearn.tree import DecisionTreeClassifier\n",
    "            from lightgbm import LGBMClassifier\n",
    "            from xgboost  import XGBRFClassifier\n",
    "\n",
    "            # Setting Models\n",
    "            nb = GaussianNB()\n",
    "            rf = RandomForestClassifier(criterion=\"entropy\", n_estimators=500, max_depth=6)\n",
    "            lr = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
    "            dt = DecisionTreeClassifier(max_depth=13,  min_samples_leaf=10)\n",
    "            xgb = XGBRFClassifier(max_depth=10,learning_rate=0.1)\n",
    "            lgbm_rf = LGBMClassifier(boosting_type='rf',n_jobs=1, bagging_freq=3, bagging_fraction=.3,importance_type='gain')\n",
    "            lgbm_dart = LGBMClassifier(boosting_type='dart',n_jobs=1, importance_type='gain')\n",
    "            lgbm = LGBMClassifier(n_jobs=1, importance_type='gain')\n",
    "\n",
    "            # Evaluating\n",
    "            model_list = [nb, lr, dt, rf, xgb, lgbm_rf, lgbm_dart, lgbm]\n",
    "            for model in model_list:\n",
    "                print(model)\n",
    "                ob2.train_predict_model(model)\n",
    "                print()\n",
    "            ob2 = modeling(self.X_train, self.X_test, self.y_train, self.y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ob.dataset\n",
    "y = dataset['Survived']\n",
    "X = dataset[dataset.columns[1:]]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "Precision:  0.7346938775510204\n",
      "Recall:  0.7272727272727273\n",
      "Accuracy:  0.8022388059701493\n",
      "F1:  0.730964467005076\n",
      "AUC:  0.8388022234176081\n",
      "Confusion Matrix: \n",
      "  [[143  26]\n",
      " [ 27  72]]\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=1000, multi_class='warn',\n",
      "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
      "          tol=0.0001, verbose=0, warm_start=False)\n",
      "Precision:  0.6938775510204082\n",
      "Recall:  0.6868686868686869\n",
      "Accuracy:  0.7723880597014925\n",
      "F1:  0.6903553299492386\n",
      "AUC:  0.834439065208296\n",
      "Confusion Matrix: \n",
      "  [[139  30]\n",
      " [ 31  68]]\n",
      "\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=13,\n",
      "            max_features=None, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=10, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
      "            splitter='best')\n",
      "Precision:  0.7191011235955056\n",
      "Recall:  0.6464646464646465\n",
      "Accuracy:  0.7761194029850746\n",
      "F1:  0.6808510638297872\n",
      "AUC:  0.8216185523877833\n",
      "Confusion Matrix: \n",
      "  [[144  25]\n",
      " [ 35  64]]\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
      "            max_depth=6, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=500, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Precision:  0.7875\n",
      "Recall:  0.6363636363636364\n",
      "Accuracy:  0.8022388059701493\n",
      "F1:  0.7039106145251396\n",
      "AUC:  0.8440918056302672\n",
      "Confusion Matrix: \n",
      "  [[152  17]\n",
      " [ 36  63]]\n",
      "\n",
      "XGBRFClassifier(base_score=0.5, colsample_bylevel=1, colsample_bynode=0.8,\n",
      "        colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
      "        max_depth=10, min_child_weight=1, missing=None, n_estimators=100,\n",
      "        n_jobs=1, nthread=None, objective='binary:logistic',\n",
      "        random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "        seed=None, silent=None, subsample=0.8, verbosity=1)\n",
      "Precision:  0.7857142857142857\n",
      "Recall:  0.6666666666666666\n",
      "Accuracy:  0.8097014925373134\n",
      "F1:  0.721311475409836\n",
      "AUC:  0.8434044587890743\n",
      "Confusion Matrix: \n",
      "  [[151  18]\n",
      " [ 33  66]]\n",
      "\n",
      "LGBMClassifier(bagging_fraction=0.3, bagging_freq=3, boosting_type='rf',\n",
      "        class_weight=None, colsample_bytree=1.0, importance_type='gain',\n",
      "        learning_rate=0.1, max_depth=-1, min_child_samples=20,\n",
      "        min_child_weight=0.001, min_split_gain=0.0, n_estimators=100,\n",
      "        n_jobs=1, num_leaves=31, objective=None, random_state=None,\n",
      "        reg_alpha=0.0, reg_lambda=0.0, silent=True, subsample=1.0,\n",
      "        subsample_for_bin=200000, subsample_freq=0)\n",
      "Precision:  0.7866666666666666\n",
      "Recall:  0.5959595959595959\n",
      "Accuracy:  0.7910447761194029\n",
      "F1:  0.6781609195402297\n",
      "AUC:  0.8337517183671029\n",
      "Confusion Matrix: \n",
      "  [[153  16]\n",
      " [ 40  59]]\n",
      "\n",
      "LGBMClassifier(boosting_type='dart', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='gain', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "Precision:  0.7840909090909091\n",
      "Recall:  0.696969696969697\n",
      "Accuracy:  0.8171641791044776\n",
      "F1:  0.7379679144385027\n",
      "AUC:  0.8366206443129519\n",
      "Confusion Matrix: \n",
      "  [[150  19]\n",
      " [ 30  69]]\n",
      "\n",
      "LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,\n",
      "        importance_type='gain', learning_rate=0.1, max_depth=-1,\n",
      "        min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,\n",
      "        n_estimators=100, n_jobs=1, num_leaves=31, objective=None,\n",
      "        random_state=None, reg_alpha=0.0, reg_lambda=0.0, silent=True,\n",
      "        subsample=1.0, subsample_for_bin=200000, subsample_freq=0)\n",
      "Precision:  0.7558139534883721\n",
      "Recall:  0.6565656565656566\n",
      "Accuracy:  0.7947761194029851\n",
      "F1:  0.7027027027027027\n",
      "AUC:  0.8370390293467216\n",
      "Confusion Matrix: \n",
      "  [[148  21]\n",
      " [ 34  65]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ob2 = cl_modeling(X_train, X_test, y_train, y_test)\n",
    "ob2.multi_default_models()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
